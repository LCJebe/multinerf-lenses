{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from internal import camera_utils\n",
    "from internal import configs\n",
    "from internal import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9 images.\n"
     ]
    }
   ],
   "source": [
    "config = configs.Config()\n",
    "config.dataset_loader = 'nextcam'\n",
    "config.near = 0.\n",
    "config.far = 1.\n",
    "config.factor = 8\n",
    "config.data_dir = \"/home/jebe/multinerf-lenses/data/table.npz\"\n",
    "config.llff_use_all_images_for_training = True\n",
    "dataset1 = datasets.load_dataset('train', config.data_dir, config)\n",
    "dataset1._load_renderings(config)\n",
    "print(f\"Loaded {dataset1.images.shape[0]} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(ax, p, q, color=\"r\"):\n",
    "  \"\"\"Plots a 3d line between points p and q.\"\"\"\n",
    "  x = [p[0], q[0]]\n",
    "  y = [p[1], q[1]]\n",
    "  z = [p[2], q[2]]\n",
    "  ax.plot(x, y, zs=z, color=color)\n",
    "\n",
    "def plot_pose(ax, c2w, scale):\n",
    "  \"\"\"Plots a pose.\"\"\"\n",
    "  origin = c2w[:3,3]\n",
    "  x = c2w[:3, 0]\n",
    "  y = c2w[:3, 1]\n",
    "  z = c2w[:3, 2]\n",
    "\n",
    "  line(ax, origin, origin + x*scale, \"r\")\n",
    "  line(ax, origin, origin + y*scale, \"g\")\n",
    "  line(ax, origin, origin + z*scale, \"b\")\n",
    "\n",
    "def plot_poses(camtoworlds, scale=1):\n",
    "  fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "  ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "    \n",
    "  x = camtoworlds[:, 0, 3]\n",
    "  y = camtoworlds[:, 1, 3]\n",
    "  z = camtoworlds[:, 2, 3]\n",
    "  ax.scatter3D(x, y, z, c=np.linspace(0, 1, x.shape[0]), cmap='viridis', marker='o', s=50, alpha=0.7)\n",
    "    \n",
    "  for c2w in camtoworlds:\n",
    "    plot_pose(ax, c2w, scale)\n",
    "    \n",
    "  ax.set_xlabel(\"X\")\n",
    "  ax.set_ylabel(\"Y\")\n",
    "  ax.set_zlabel(\"Z\")\n",
    "#   ax.set_xlim([-1.1, 1.1])\n",
    "#   ax.set_ylim([-1.1, 1.1])\n",
    "#   ax.set_zlim([-1.1, 1.1])\n",
    "    \n",
    "def world_from_pix_and_z(p2c, c2w, pixel_grid, depth, conf):\n",
    "  # Homogeneous coords: (u, v, 1, 1/z)\n",
    "  # Shape: [4, H, W]\n",
    "  pix_h = np.stack([pixel_grid[0], pixel_grid[1], np.ones_like(depth), 1/depth])\n",
    "  # Shape [4, H*W]\n",
    "  pix_h = np.reshape(pix_h, (pix_h.shape[0], np.prod(pix_h.shape[1:])))\n",
    "  depth = np.reshape(depth, (np.prod(depth.shape)))\n",
    "  conf = np.reshape(conf, (np.prod(conf.shape)))\n",
    "\n",
    "  # Convert c2w from OpenGL to OpenCV\n",
    "  c2w = c2w @ np.diag([1, -1, -1, 1])\n",
    "  \n",
    "  points = c2w @ p2c @ pix_h * depth\n",
    "\n",
    "\n",
    "  return points[:, conf * 255 > 1.5]\n",
    "\n",
    "def get_pixel_grid(width, height):\n",
    "  return np.array(np.meshgrid(np.arange(width), np.arange(height), indexing='xy'))\n",
    "\n",
    "def save_pointcloud(points, filename):\n",
    "    # Pass xyz to Open3D.o3d.geometry.PointCloud and visualize\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    points_formatted = points.T[:, :3]\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_formatted)\n",
    "    o3d.io.write_point_cloud(filename, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:  3.3568457518082844\n"
     ]
    }
   ],
   "source": [
    "pixel_grid = get_pixel_grid(dataset1.width, dataset1.height)\n",
    "scale = np.linalg.norm(dataset1.debug_transform[0, :3])\n",
    "#scale = 1\n",
    "print(\"scale: \", scale)\n",
    "\n",
    "for i in [0, 8]:\n",
    "  # Extend matrices to 4x4\n",
    "  p2c = np.eye(4)\n",
    "  p2c[:3, :3] = dataset1.pixtocams[i]\n",
    "  c2w = np.eye(4)\n",
    "  c2w[:3, :4] = dataset1.camtoworlds[i, :3, :4]\n",
    "\n",
    "  depth = dataset1.depths[i]\n",
    "  depth_scaled = depth * scale\n",
    "    \n",
    "  points = world_from_pix_and_z(p2c, c2w, pixel_grid, depth_scaled, dataset1.confidences[i])\n",
    "  save_pointcloud(points, f\"test_{i}.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_poses(dataset1.camtoworlds, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all images\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "for i, img in enumerate(dataset1.images):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset1.debug_transform)\n",
    "for i in range(3):\n",
    "    print(np.linalg.norm(dataset1.debug_transform[i, :3]))\n",
    "    print(np.linalg.norm(dataset1.debug_transform[:3, i]))\n",
    "#print(dataset1.camtoworlds[0])\n",
    "#print(np.linalg.inv(dataset1.pixtocams[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLFF Dataset comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configs.Config()\n",
    "config.dataset_loader = 'llff'\n",
    "config.near = 0.\n",
    "config.far = 1.\n",
    "config.factor = 8\n",
    "config.data_dir = \"/home/jebe/multinerf/data/fern\"\n",
    "dataset2 = datasets.load_dataset('train', config.data_dir, config)\n",
    "dataset2._load_renderings(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_poses(dataset2.camtoworlds, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "n_images = dataset2.images.shape[0]\n",
    "for i, img in enumerate(dataset2.images):\n",
    "    plt.subplot(int(np.ceil(n_images / 4)), 4, i+1)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset2.camtoworlds[0])\n",
    "print(dataset2.pixtocams[0])\n",
    "print(dataset2.pixtocams.shape)\n",
    "print(np.linalg.inv(dataset2.pixtocams))\n",
    "for i in range(3):\n",
    "    print(np.linalg.norm(dataset2.camtoworlds[0, i, :3]))\n",
    "    print(np.linalg.norm(dataset2.camtoworlds[0, :3, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First and last image.\n",
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(dataset2.images[0])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(dataset2.images[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset2.images[0].dtype)\n",
    "print(dataset2.images[0].shape)\n",
    "print(np.min(dataset2.images[0]))\n",
    "print(np.max(dataset2.images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b8177ec4640c0b0de295e88c2cfc4bbde7cddab2a27cf44487a54fa4a118911"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
