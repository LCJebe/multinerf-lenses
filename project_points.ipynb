{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/table.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(npz_file):\n",
    "  bundle = np.load(npz_file, allow_pickle=True)\n",
    "  num_frames = bundle[\"num_frames\"]\n",
    "\n",
    "  # Extract poses, intrinsics, images.\n",
    "  images = []\n",
    "  camtoworlds = []\n",
    "  pixtocams = []\n",
    "  depths = []\n",
    "  confidences = []\n",
    "  for i in range(num_frames):\n",
    "    # Poses.\n",
    "    w2c = bundle[f\"info_{i}\"].item()[\"world_to_camera\"]\n",
    "    camtoworlds.append(np.linalg.inv(w2c))\n",
    "\n",
    "    # Intrinsics.\n",
    "    # Swap x and y of principal point values in K.\n",
    "    K_local = bundle[f\"info_{i}\"].item()[\"intrinsics\"]\n",
    "    camera_mat = np.eye(4)\n",
    "    camera_mat[:3, :3] = K_local.copy()\n",
    "    camera_mat[0, 2] = K_local[1, 2]\n",
    "    camera_mat[1, 2] = K_local[0, 2]\n",
    "\n",
    "    scale_factor = 1920 / 256\n",
    "    camera_mat = np.diag([1. / scale_factor, 1. / scale_factor, 1., 1.\n",
    "                  ]).astype(np.float32) @ camera_mat\n",
    "\n",
    "    pixtocams.append(np.linalg.inv(camera_mat))\n",
    "\n",
    "\n",
    "    # Images.\n",
    "    image = (bundle[f\"img_{i}\"] / 255.).astype(np.float32)\n",
    "    image = skimage.transform.resize(image, (256, 192))\n",
    "    images.append(image)\n",
    "\n",
    "    # Depthmaps.\n",
    "    depths.append(bundle[f\"depth_{i}\"])\n",
    "    confidences.append(bundle[f\"conf_{i}\"])\n",
    "\n",
    "  return np.stack(camtoworlds), np.stack(pixtocams), np.stack(images), np.stack(depths), np.stack(confidences)\n",
    "\n",
    "def world_from_pix_and_z(p2c, c2w, pixel_grid, depth, conf):\n",
    "  # Homogeneous coords: (u, v, 1, 1/z)\n",
    "  # Shape: [4, H, W]\n",
    "  pix_h = np.stack([pixel_grid[0], pixel_grid[1], np.ones_like(depth), 1/depth])\n",
    "  # Shape [4, H*W]\n",
    "  pix_h = np.reshape(pix_h, (pix_h.shape[0], np.prod(pix_h.shape[1:])))\n",
    "  depth = np.reshape(depth, (np.prod(depth.shape)))\n",
    "  conf = np.reshape(conf, (np.prod(conf.shape)))\n",
    "\n",
    "  # Convert c2w from OpenGL to OpenCV\n",
    "  c2w = c2w @ np.diag([1, -1, -1, 1])\n",
    "  \n",
    "  points = c2w @ p2c @ pix_h * depth\n",
    "\n",
    "  return points[:, conf == 2]\n",
    "\n",
    "def get_pixel_grid(width, height):\n",
    "  return np.meshgrid(np.arange(width), np.arange(height), indexing='xy')\n",
    "\n",
    "\n",
    "def save_pointcloud(points, filename):\n",
    "    # Pass xyz to Open3D.o3d.geometry.PointCloud and visualize\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    points_formatted = points.T[:, :3]\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_formatted)\n",
    "    o3d.io.write_point_cloud(filename, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "camtoworlds, pixtocams, images, depths, confidences = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = images.shape[1:3]\n",
    "pixel_grid = get_pixel_grid(width, height)\n",
    "for i in [0, 8]:\n",
    "  points = world_from_pix_and_z(pixtocams[i], camtoworlds[i], pixel_grid, depths[i], confidences[i])\n",
    "  save_pointcloud(points, f\"test_{i}.ply\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# for i in range(9):\n",
    "#     filename = f\"data/table/images/img_{i:02}.png\"\n",
    "#     imageio.imsave(filename, np.clip(images[i] * 255, 0, 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3a631742964f036320f067672256ff165c34430924b801afe65a9f19e72b056"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
